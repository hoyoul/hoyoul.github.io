<!DOCTYPE html>
<html>
  <head><title>[ppt] chapter5- DQN 소스 분석</title>


<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="apple-mobile-web-app-capable" content="yes" />

<link rel="shortcut icon" href="./img/favicon.ico" type="image/x-icon">
<link rel="icon" href="./img/favicon.ico" type="image/x-icon">    

<link rel="stylesheet" href="/css/main.css">

</head>
  <body><header>
  <a href="/" id="logo">
    <img src="http://braindump.frege2godel.me/img/mylogo.png" alt="holy frege">
    <h3><span>H</span>oly <span>F</span>rege's <span id="note">notes</span></h3>
  </a>
    <small>G.frege를 너무 사랑하는 holy가...</small>  
</header>

<div class="container">
  <div class="page">
    <h1 class="collapsed-title">[ppt] chapter5- DQN 소스 분석</h1>    
      <div class="content">
	<a href="http://braindump.frege2godel.me/postss/20220214181304-note_dqn_%E1%84%89%E1%85%A9%E1%84%89%E1%85%B3_%E1%84%87%E1%85%AE%E1%86%AB%E1%84%89%E1%85%A5%E1%86%A8/" alt="[ppt] chapter5- DQN 소스 분석" class="permalink"><h1>[ppt] chapter5- DQN 소스 분석</h1></a>      
	<h2 id="dqn-소스-분석">DQN 소스 분석</h2>
<ul>
<li>off-policy의 장점을 가져옴. (q learning 방식)</li>
<li>replay메모리를 사용해서 샘플을 저장했다가, 학습에 이용.</li>
<li>신경망이 2개다. model과 target model.</li>
</ul>
<h3 id="q-learning에-대해서">Q-learning에 대해서</h3>
<ul>
<li>Salsa와 다르게 Q-learning은 behavior policy와 target policy가 다르다.</li>
<li>Salsa는 한 step 이동한후에 update가 되지만, Q-learning은 update할때, 그 상태에서의 최대인 q를 찾아서 update했다.</li>
<li>Salsa에서는 한 step이동한후 다음 q값이 장애물이 있다고 해도 update한다. 이것이 계속 학습될 경우 문제가 된다.</li>
<li>Q-learning에서는 update할 다음 q값이 max q값이다.</li>
</ul>
<h3 id="dqn-loss-function">DQN loss function</h3>
<ul>
<li>q learning에서 max q값이 DQN에서는 정답에 해당하고, target network가 이를 담당한다.</li>
<li>target network은 정답으로 사용되며, 에피소드마다 model network로부터 가중치를 가져온다.</li>
<li>loss function</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/ppt_rl/loss_dqn.jpeg"
         alt="Figure 1: loss function" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 1: </span>loss function</p>
        </figcaption>
</figure>

<h3 id="dqn-optimization-function">DQN optimization function</h3>
<ul>
<li>가중치가 update되는것은 model network다.</li>
<li>target network의 update는 model로부터 가져온다.</li>
</ul>
<h3 id="dqn">DQN</h3>
<ul>
<li>프로그램 실행 과정</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/ppt_rl/dqn.jpeg" width="400px"/>
</figure>

<h2 id="소스-분석">소스 분석</h2>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#007020;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">os</span>
</span></span><span style="display:flex;"><span><span style="color:#007020;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">sys</span>
</span></span><span style="display:flex;"><span><span style="color:#007020;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">gym</span>
</span></span><span style="display:flex;"><span><span style="color:#007020;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">pylab</span>
</span></span><span style="display:flex;"><span><span style="color:#007020;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">random</span>
</span></span><span style="display:flex;"><span><span style="color:#007020;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">numpy</span> <span style="color:#007020;font-weight:bold">as</span> <span style="color:#0e84b5;font-weight:bold">np</span>
</span></span><span style="display:flex;"><span><span style="color:#007020;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">collections</span> <span style="color:#007020;font-weight:bold">import</span> deque
</span></span><span style="display:flex;"><span><span style="color:#007020;font-weight:bold">import</span> <span style="color:#0e84b5;font-weight:bold">tensorflow</span> <span style="color:#007020;font-weight:bold">as</span> <span style="color:#0e84b5;font-weight:bold">tf</span>
</span></span><span style="display:flex;"><span><span style="color:#007020;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">tensorflow.keras.layers</span> <span style="color:#007020;font-weight:bold">import</span> Dense
</span></span><span style="display:flex;"><span><span style="color:#007020;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">tensorflow.keras.optimizers</span> <span style="color:#007020;font-weight:bold">import</span> Adam
</span></span><span style="display:flex;"><span><span style="color:#007020;font-weight:bold">from</span> <span style="color:#0e84b5;font-weight:bold">tensorflow.keras.initializers</span> <span style="color:#007020;font-weight:bold">import</span> RandomUniform
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#60a0b0;font-style:italic"># 상태가 입력, 큐함수가 출력인 인공신경망 생성</span>
</span></span><span style="display:flex;"><span><span style="color:#007020;font-weight:bold">class</span> <span style="color:#0e84b5;font-weight:bold">DQN</span>(tf<span style="color:#666">.</span>keras<span style="color:#666">.</span>Model):
</span></span><span style="display:flex;"><span>    <span style="color:#007020;font-weight:bold">def</span> __init__(self, action_size):
</span></span><span style="display:flex;"><span>	<span style="color:#007020">super</span>(DQN, self)<span style="color:#666">.</span>__init__()
</span></span><span style="display:flex;"><span>	self<span style="color:#666">.</span>fc1 <span style="color:#666">=</span> Dense(<span style="color:#40a070">24</span>, activation<span style="color:#666">=</span><span style="color:#4070a0">&#39;relu&#39;</span>)
</span></span><span style="display:flex;"><span>	self<span style="color:#666">.</span>fc2 <span style="color:#666">=</span> Dense(<span style="color:#40a070">24</span>, activation<span style="color:#666">=</span><span style="color:#4070a0">&#39;relu&#39;</span>)
</span></span><span style="display:flex;"><span>	self<span style="color:#666">.</span>fc_out <span style="color:#666">=</span> Dense(action_size,
</span></span><span style="display:flex;"><span>			    kernel_initializer<span style="color:#666">=</span>RandomUniform(<span style="color:#666">-</span><span style="color:#40a070">1e-3</span>, <span style="color:#40a070">1e-3</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">call</span>(self, x):
</span></span><span style="display:flex;"><span>	x <span style="color:#666">=</span> self<span style="color:#666">.</span>fc1(x)
</span></span><span style="display:flex;"><span>	x <span style="color:#666">=</span> self<span style="color:#666">.</span>fc2(x)
</span></span><span style="display:flex;"><span>	q <span style="color:#666">=</span> self<span style="color:#666">.</span>fc_out(x)
</span></span><span style="display:flex;"><span>	<span style="color:#007020;font-weight:bold">return</span> q
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#60a0b0;font-style:italic"># 카트폴 예제에서의 DQN 에이전트</span>
</span></span><span style="display:flex;"><span><span style="color:#007020;font-weight:bold">class</span> <span style="color:#0e84b5;font-weight:bold">DQNAgent</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#007020;font-weight:bold">def</span> __init__(self, state_size, action_size):
</span></span><span style="display:flex;"><span>	self<span style="color:#666">.</span>render <span style="color:#666">=</span> <span style="color:#007020;font-weight:bold">False</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#60a0b0;font-style:italic"># 상태와 행동의 크기 정의</span>
</span></span><span style="display:flex;"><span>	self<span style="color:#666">.</span>state_size <span style="color:#666">=</span> state_size
</span></span><span style="display:flex;"><span>	self<span style="color:#666">.</span>action_size <span style="color:#666">=</span> action_size
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#60a0b0;font-style:italic"># DQN 하이퍼파라미터</span>
</span></span><span style="display:flex;"><span>	self<span style="color:#666">.</span>discount_factor <span style="color:#666">=</span> <span style="color:#40a070">0.99</span>
</span></span><span style="display:flex;"><span>	self<span style="color:#666">.</span>learning_rate <span style="color:#666">=</span> <span style="color:#40a070">0.001</span>
</span></span><span style="display:flex;"><span>	self<span style="color:#666">.</span>epsilon <span style="color:#666">=</span> <span style="color:#40a070">1.0</span>
</span></span><span style="display:flex;"><span>	self<span style="color:#666">.</span>epsilon_decay <span style="color:#666">=</span> <span style="color:#40a070">0.999</span>
</span></span><span style="display:flex;"><span>	self<span style="color:#666">.</span>epsilon_min <span style="color:#666">=</span> <span style="color:#40a070">0.01</span>
</span></span><span style="display:flex;"><span>	self<span style="color:#666">.</span>batch_size <span style="color:#666">=</span> <span style="color:#40a070">64</span>
</span></span><span style="display:flex;"><span>	self<span style="color:#666">.</span>train_start <span style="color:#666">=</span> <span style="color:#40a070">1000</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#60a0b0;font-style:italic"># 리플레이 메모리, 최대 크기 2000</span>
</span></span><span style="display:flex;"><span>	self<span style="color:#666">.</span>memory <span style="color:#666">=</span> deque(maxlen<span style="color:#666">=</span><span style="color:#40a070">2000</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#60a0b0;font-style:italic"># 모델과 타깃 모델 생성</span>
</span></span><span style="display:flex;"><span>	self<span style="color:#666">.</span>model <span style="color:#666">=</span> DQN(action_size)
</span></span><span style="display:flex;"><span>	self<span style="color:#666">.</span>target_model <span style="color:#666">=</span> DQN(action_size)
</span></span><span style="display:flex;"><span>	self<span style="color:#666">.</span>optimizer <span style="color:#666">=</span> Adam(lr<span style="color:#666">=</span>self<span style="color:#666">.</span>learning_rate)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#60a0b0;font-style:italic"># 타깃 모델 초기화</span>
</span></span><span style="display:flex;"><span>	self<span style="color:#666">.</span>update_target_model()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#60a0b0;font-style:italic"># 타깃 모델을 모델의 가중치로 업데이트</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">update_target_model</span>(self):
</span></span><span style="display:flex;"><span>	self<span style="color:#666">.</span>target_model<span style="color:#666">.</span>set_weights(self<span style="color:#666">.</span>model<span style="color:#666">.</span>get_weights())
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#60a0b0;font-style:italic"># 입실론 탐욕 정책으로 행동 선택</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">get_action</span>(self, state):
</span></span><span style="display:flex;"><span>	<span style="color:#007020;font-weight:bold">if</span> np<span style="color:#666">.</span>random<span style="color:#666">.</span>rand() <span style="color:#666">&lt;=</span> self<span style="color:#666">.</span>epsilon:
</span></span><span style="display:flex;"><span>	    <span style="color:#007020;font-weight:bold">return</span> random<span style="color:#666">.</span>randrange(self<span style="color:#666">.</span>action_size)
</span></span><span style="display:flex;"><span>	<span style="color:#007020;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>	    q_value <span style="color:#666">=</span> self<span style="color:#666">.</span>model(state)
</span></span><span style="display:flex;"><span>	    <span style="color:#007020;font-weight:bold">return</span> np<span style="color:#666">.</span>argmax(q_value[<span style="color:#40a070">0</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#60a0b0;font-style:italic"># 샘플 &lt;s, a, r, s&#39;&gt;을 리플레이 메모리에 저장</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">append_sample</span>(self, state, action, reward, next_state, done):
</span></span><span style="display:flex;"><span>	self<span style="color:#666">.</span>memory<span style="color:#666">.</span>append((state, action, reward, next_state, done))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#60a0b0;font-style:italic"># 리플레이 메모리에서 무작위로 추출한 배치로 모델 학습</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007020;font-weight:bold">def</span> <span style="color:#06287e">train_model</span>(self):
</span></span><span style="display:flex;"><span>	<span style="color:#007020;font-weight:bold">if</span> self<span style="color:#666">.</span>epsilon <span style="color:#666">&gt;</span> self<span style="color:#666">.</span>epsilon_min:
</span></span><span style="display:flex;"><span>	    self<span style="color:#666">.</span>epsilon <span style="color:#666">*=</span> self<span style="color:#666">.</span>epsilon_decay
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#60a0b0;font-style:italic"># 메모리에서 배치 크기만큼 무작위로 샘플 추출</span>
</span></span><span style="display:flex;"><span>	mini_batch <span style="color:#666">=</span> random<span style="color:#666">.</span>sample(self<span style="color:#666">.</span>memory, self<span style="color:#666">.</span>batch_size)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	states <span style="color:#666">=</span> np<span style="color:#666">.</span>array([sample[<span style="color:#40a070">0</span>][<span style="color:#40a070">0</span>] <span style="color:#007020;font-weight:bold">for</span> sample <span style="color:#007020;font-weight:bold">in</span> mini_batch])
</span></span><span style="display:flex;"><span>	actions <span style="color:#666">=</span> np<span style="color:#666">.</span>array([sample[<span style="color:#40a070">1</span>] <span style="color:#007020;font-weight:bold">for</span> sample <span style="color:#007020;font-weight:bold">in</span> mini_batch])
</span></span><span style="display:flex;"><span>	rewards <span style="color:#666">=</span> np<span style="color:#666">.</span>array([sample[<span style="color:#40a070">2</span>] <span style="color:#007020;font-weight:bold">for</span> sample <span style="color:#007020;font-weight:bold">in</span> mini_batch])
</span></span><span style="display:flex;"><span>	next_states <span style="color:#666">=</span> np<span style="color:#666">.</span>array([sample[<span style="color:#40a070">3</span>][<span style="color:#40a070">0</span>] <span style="color:#007020;font-weight:bold">for</span> sample <span style="color:#007020;font-weight:bold">in</span> mini_batch])
</span></span><span style="display:flex;"><span>	dones <span style="color:#666">=</span> np<span style="color:#666">.</span>array([sample[<span style="color:#40a070">4</span>] <span style="color:#007020;font-weight:bold">for</span> sample <span style="color:#007020;font-weight:bold">in</span> mini_batch])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#60a0b0;font-style:italic"># 학습 파라메터</span>
</span></span><span style="display:flex;"><span>	model_params <span style="color:#666">=</span> self<span style="color:#666">.</span>model<span style="color:#666">.</span>trainable_variables
</span></span><span style="display:flex;"><span>	<span style="color:#007020;font-weight:bold">with</span> tf<span style="color:#666">.</span>GradientTape() <span style="color:#007020;font-weight:bold">as</span> tape:
</span></span><span style="display:flex;"><span>	    <span style="color:#60a0b0;font-style:italic"># 현재 상태에 대한 모델의 큐함수</span>
</span></span><span style="display:flex;"><span>	    predicts <span style="color:#666">=</span> self<span style="color:#666">.</span>model(states)
</span></span><span style="display:flex;"><span>	    one_hot_action <span style="color:#666">=</span> tf<span style="color:#666">.</span>one_hot(actions, self<span style="color:#666">.</span>action_size)
</span></span><span style="display:flex;"><span>	    predicts <span style="color:#666">=</span> tf<span style="color:#666">.</span>reduce_sum(one_hot_action <span style="color:#666">*</span> predicts, axis<span style="color:#666">=</span><span style="color:#40a070">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	    <span style="color:#60a0b0;font-style:italic"># 다음 상태에 대한 타깃 모델의 큐함수</span>
</span></span><span style="display:flex;"><span>	    target_predicts <span style="color:#666">=</span> self<span style="color:#666">.</span>target_model(next_states)
</span></span><span style="display:flex;"><span>	    target_predicts <span style="color:#666">=</span> tf<span style="color:#666">.</span>stop_gradient(target_predicts)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	    <span style="color:#60a0b0;font-style:italic"># 벨만 최적 방정식을 이용한 업데이트 타깃</span>
</span></span><span style="display:flex;"><span>	    max_q <span style="color:#666">=</span> np<span style="color:#666">.</span>amax(target_predicts, axis<span style="color:#666">=-</span><span style="color:#40a070">1</span>)
</span></span><span style="display:flex;"><span>	    targets <span style="color:#666">=</span> rewards <span style="color:#666">+</span> (<span style="color:#40a070">1</span> <span style="color:#666">-</span> dones) <span style="color:#666">*</span> self<span style="color:#666">.</span>discount_factor <span style="color:#666">*</span> max_q
</span></span><span style="display:flex;"><span>	    loss <span style="color:#666">=</span> tf<span style="color:#666">.</span>reduce_mean(tf<span style="color:#666">.</span>square(targets <span style="color:#666">-</span> predicts))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#60a0b0;font-style:italic"># 오류함수를 줄이는 방향으로 모델 업데이트</span>
</span></span><span style="display:flex;"><span>	grads <span style="color:#666">=</span> tape<span style="color:#666">.</span>gradient(loss, model_params)
</span></span><span style="display:flex;"><span>	self<span style="color:#666">.</span>optimizer<span style="color:#666">.</span>apply_gradients(<span style="color:#007020">zip</span>(grads, model_params))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#007020;font-weight:bold">if</span> __name__ <span style="color:#666">==</span> <span style="color:#4070a0">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#60a0b0;font-style:italic"># CartPole-v1 환경, 최대 타임스텝 수가 500</span>
</span></span><span style="display:flex;"><span>    env <span style="color:#666">=</span> gym<span style="color:#666">.</span>make(<span style="color:#4070a0">&#39;CartPole-v1&#39;</span>)
</span></span><span style="display:flex;"><span>    state_size <span style="color:#666">=</span> env<span style="color:#666">.</span>observation_space<span style="color:#666">.</span>shape[<span style="color:#40a070">0</span>]
</span></span><span style="display:flex;"><span>    action_size <span style="color:#666">=</span> env<span style="color:#666">.</span>action_space<span style="color:#666">.</span>n
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#60a0b0;font-style:italic"># DQN 에이전트 생성</span>
</span></span><span style="display:flex;"><span>    agent <span style="color:#666">=</span> DQNAgent(state_size, action_size)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    scores, episodes <span style="color:#666">=</span> [], []
</span></span><span style="display:flex;"><span>    score_avg <span style="color:#666">=</span> <span style="color:#40a070">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    num_episode <span style="color:#666">=</span> <span style="color:#40a070">300</span>
</span></span><span style="display:flex;"><span>    <span style="color:#007020;font-weight:bold">for</span> e <span style="color:#007020;font-weight:bold">in</span> <span style="color:#007020">range</span>(num_episode):
</span></span><span style="display:flex;"><span>	done <span style="color:#666">=</span> <span style="color:#007020;font-weight:bold">False</span>
</span></span><span style="display:flex;"><span>	score <span style="color:#666">=</span> <span style="color:#40a070">0</span>
</span></span><span style="display:flex;"><span>	<span style="color:#60a0b0;font-style:italic"># env 초기화</span>
</span></span><span style="display:flex;"><span>	state <span style="color:#666">=</span> env<span style="color:#666">.</span>reset()
</span></span><span style="display:flex;"><span>	state <span style="color:#666">=</span> np<span style="color:#666">.</span>reshape(state, [<span style="color:#40a070">1</span>, state_size])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	<span style="color:#007020;font-weight:bold">while</span> <span style="color:#007020;font-weight:bold">not</span> done:
</span></span><span style="display:flex;"><span>	    <span style="color:#007020;font-weight:bold">if</span> agent<span style="color:#666">.</span>render:
</span></span><span style="display:flex;"><span>		env<span style="color:#666">.</span>render()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	    <span style="color:#60a0b0;font-style:italic"># 현재 상태로 행동을 선택</span>
</span></span><span style="display:flex;"><span>	    action <span style="color:#666">=</span> agent<span style="color:#666">.</span>get_action(state)
</span></span><span style="display:flex;"><span>	    <span style="color:#60a0b0;font-style:italic"># 선택한 행동으로 환경에서 한 타임스텝 진행</span>
</span></span><span style="display:flex;"><span>	    next_state, reward, done, info <span style="color:#666">=</span> env<span style="color:#666">.</span>step(action)
</span></span><span style="display:flex;"><span>	    next_state <span style="color:#666">=</span> np<span style="color:#666">.</span>reshape(next_state, [<span style="color:#40a070">1</span>, state_size])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	    <span style="color:#60a0b0;font-style:italic"># 타임스텝마다 보상 0.1, 에피소드가 중간에 끝나면 -1 보상</span>
</span></span><span style="display:flex;"><span>	    score <span style="color:#666">+=</span> reward
</span></span><span style="display:flex;"><span>	    reward <span style="color:#666">=</span> <span style="color:#40a070">0.1</span> <span style="color:#007020;font-weight:bold">if</span> <span style="color:#007020;font-weight:bold">not</span> done <span style="color:#007020;font-weight:bold">or</span> score <span style="color:#666">==</span> <span style="color:#40a070">500</span> <span style="color:#007020;font-weight:bold">else</span> <span style="color:#666">-</span><span style="color:#40a070">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	    <span style="color:#60a0b0;font-style:italic"># 리플레이 메모리에 샘플 &lt;s, a, r, s&#39;&gt; 저장</span>
</span></span><span style="display:flex;"><span>	    agent<span style="color:#666">.</span>append_sample(state, action, reward, next_state, done)
</span></span><span style="display:flex;"><span>	    <span style="color:#60a0b0;font-style:italic"># 매 타임스텝마다 학습</span>
</span></span><span style="display:flex;"><span>	    <span style="color:#007020;font-weight:bold">if</span> <span style="color:#007020">len</span>(agent<span style="color:#666">.</span>memory) <span style="color:#666">&gt;=</span> agent<span style="color:#666">.</span>train_start:
</span></span><span style="display:flex;"><span>		agent<span style="color:#666">.</span>train_model()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	    state <span style="color:#666">=</span> next_state
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	    <span style="color:#007020;font-weight:bold">if</span> done:
</span></span><span style="display:flex;"><span>		<span style="color:#60a0b0;font-style:italic"># 각 에피소드마다 타깃 모델을 모델의 가중치로 업데이트</span>
</span></span><span style="display:flex;"><span>		agent<span style="color:#666">.</span>update_target_model()
</span></span><span style="display:flex;"><span>		<span style="color:#60a0b0;font-style:italic"># 에피소드마다 학습 결과 출력</span>
</span></span><span style="display:flex;"><span>		score_avg <span style="color:#666">=</span> <span style="color:#40a070">0.9</span> <span style="color:#666">*</span> score_avg <span style="color:#666">+</span> <span style="color:#40a070">0.1</span> <span style="color:#666">*</span> score <span style="color:#007020;font-weight:bold">if</span> score_avg <span style="color:#666">!=</span> <span style="color:#40a070">0</span> <span style="color:#007020;font-weight:bold">else</span> score
</span></span><span style="display:flex;"><span>		<span style="color:#007020">print</span>(<span style="color:#4070a0">&#34;episode: </span><span style="color:#70a0d0">{:3d}</span><span style="color:#4070a0"> | score avg: </span><span style="color:#70a0d0">{:3.2f}</span><span style="color:#4070a0"> | memory length: </span><span style="color:#70a0d0">{:4d}</span><span style="color:#4070a0"> | epsilon: </span><span style="color:#70a0d0">{:.4f}</span><span style="color:#4070a0">&#34;</span><span style="color:#666">.</span>format(
</span></span><span style="display:flex;"><span>		      e, score_avg, <span style="color:#007020">len</span>(agent<span style="color:#666">.</span>memory), agent<span style="color:#666">.</span>epsilon))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		<span style="color:#60a0b0;font-style:italic"># 에피소드마다 학습 결과 그래프로 저장</span>
</span></span><span style="display:flex;"><span>		scores<span style="color:#666">.</span>append(score_avg)
</span></span><span style="display:flex;"><span>		episodes<span style="color:#666">.</span>append(e)
</span></span><span style="display:flex;"><span>		pylab<span style="color:#666">.</span>plot(episodes, scores, <span style="color:#4070a0">&#39;b&#39;</span>)
</span></span><span style="display:flex;"><span>		pylab<span style="color:#666">.</span>xlabel(<span style="color:#4070a0">&#34;episode&#34;</span>)
</span></span><span style="display:flex;"><span>		pylab<span style="color:#666">.</span>ylabel(<span style="color:#4070a0">&#34;average score&#34;</span>)
</span></span><span style="display:flex;"><span>		pylab<span style="color:#666">.</span>savefig(<span style="color:#4070a0">&#34;./save_graph/graph.png&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		<span style="color:#60a0b0;font-style:italic"># 이동 평균이 400 이상일 때 종료</span>
</span></span><span style="display:flex;"><span>		<span style="color:#007020;font-weight:bold">if</span> score_avg <span style="color:#666">&gt;</span> <span style="color:#40a070">400</span>:
</span></span><span style="display:flex;"><span>		    agent<span style="color:#666">.</span>model<span style="color:#666">.</span>save_weights(<span style="color:#4070a0">&#34;./save_model/model&#34;</span>, save_format<span style="color:#666">=</span><span style="color:#4070a0">&#34;tf&#34;</span>)
</span></span><span style="display:flex;"><span>		    sys<span style="color:#666">.</span>exit()
</span></span></code></pre></div>      
      </div>
        
  
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
  

  

  </div>
</div>  

<script src="/js/URI.js" type="text/javascript"></script>
<script src="/js/page.js" type="text/javascript"></script>
</body>
</html>
