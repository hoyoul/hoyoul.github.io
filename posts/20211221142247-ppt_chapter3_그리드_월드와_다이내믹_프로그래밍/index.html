<!DOCTYPE html>
<html>
  <head><title>[ppt_chapter3] 그리드 월드와 다이내믹 프로그래밍</title>


<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="apple-mobile-web-app-capable" content="yes" />

<link rel="shortcut icon" href="./img/favicon.ico" type="image/x-icon">
<link rel="icon" href="./img/favicon.ico" type="image/x-icon">    

<link rel="stylesheet" href="/css/main.css">

</head>
  <body><header>
  <a href="/" id="logo">
    <img src="http://braindump.frege2godel.me/img/mylogo.png" alt="holy frege">
    <h3><span>H</span>oly <span>F</span>rege's <span id="note">notes</span></h3>
  </a>
    <small>G.frege를 너무 사랑하는 holy가...</small>  
</header>

<div class="container">
  <div class="page">
    <h1 class="collapsed-title">[ppt_chapter3] 그리드 월드와 다이내믹 프로그래밍</h1>    
      <div class="content">
	<a href="http://braindump.frege2godel.me/posts/20211221142247-ppt_chapter3_%E1%84%80%E1%85%B3%E1%84%85%E1%85%B5%E1%84%83%E1%85%B3_%E1%84%8B%E1%85%AF%E1%86%AF%E1%84%83%E1%85%B3%E1%84%8B%E1%85%AA_%E1%84%83%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%82%E1%85%A2%E1%84%86%E1%85%B5%E1%86%A8_%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%80%E1%85%B3%E1%84%85%E1%85%A2%E1%84%86%E1%85%B5%E1%86%BC/" alt="[ppt_chapter3] 그리드 월드와 다이내믹 프로그래밍" class="permalink"><h1>[ppt_chapter3] 그리드 월드와 다이내믹 프로그래밍</h1></a>      
	<h2 id="mdp-문제의-해결">MDP 문제의 해결</h2>
<ul>
<li>DP로 문제를 해결한다는 것은 model based 방식이다. model(환경)에 대한 정보를 알때, 사용할 수 있다. <br/></li>
<li>2장에서 본 벨만 기대 방정식을 그대로 푸는것과 동일하다. <br/></li>
<li>다시 말해서, dp로 벨만 방정식을 풀기 위해선 환경과 return값을 알아야 하는데, 주어지거나 알고 있을때,사용할 수 있다. <br/></li>
</ul>
<h2 id="다이내믹-프로그래밍--dp">다이내믹 프로그래밍(DP)</h2>
<ul>
<li>벨만 방정식은 재귀함수다. 재귀함수를 풀때, 중복이 되는 값을 memoization(캐시)에 넣고 재사용해서 계산복잡도를 줄일수 있는데, 이것을 DP라고 한다. <br/></li>
<li>재귀함수나 dp나 모두 divide &amp; conquer 방식이기 때문에 문제를 작은 문제로 쪼갠다. <br/></li>
</ul>
<p><a id="figure--"></a></p>
<p><figure><img src="./img/dp1.jpeg"/>
</figure>
 <br/></p>
<h2 id="정책-이터레이션">정책 이터레이션</h2>
<ul>
<li>정책 평가와 정책발전을 교대로 한다. <br/></li>
<li>정책 평가는 주어진 policy값을 사용해서 모든 state의 value를 계산한다. <br/></li>
<li>정책 발전은 state의 value를 기반으로 모든 policy의 값을 갱신한다. <br/></li>
</ul>
<h2 id="정책-평가">정책 평가</h2>
<ul>
<li>벨만기대 방정식을 이용해서 state의 값들을 모두 계산한다. 계산된 값이 update된다. <br/></li>
</ul>
<p><a id="figure--"></a></p>
<p><figure><img src="./img/policy_iter1.jpeg"
         alt="Figure 1: policy iteration" width="500px" height="200px"/><figcaption>
            <p><span class="figure-number">Figure 1: </span>policy iteration</p>
        </figcaption>
</figure>
 <br/></p>
<h2 id="정책평가2">정책평가2</h2>
<ul>
<li>시간 t+1에서 가질수 있는 모든 상태값을 계산하기 위해선, 시간 t에서의 상태값들을 유지하고 있어야 한다. <br/></li>
</ul>
<p><a id="figure--"></a></p>
<p><figure><img src="./img/policy_iter2.jpeg" width="600px" height="350px"/>
</figure>
 <br/></p>
<h2 id="정책-발전">정책 발전</h2>
<ul>
<li>평가를 통해서 각 상태에 대한 가치를 구했기 때문에, 상태 S에서 행동으로 갈수 있는 다음 상태의 가치값들을 알 수 있다. 그 값을 이용해서 Q함수도 구할 수 있는데, Q함수로 쉽게 어떤 행동이 좋은지도 알 수 있다. <br/></li>
</ul>
<p><a id="figure--"></a></p>
<p><figure><img src="./img/q_improv1.jpeg"
         alt="Figure 2: 정책발전"/><figcaption>
            <p><span class="figure-number">Figure 2: </span>정책발전</p>
        </figcaption>
</figure>
 <br/></p>
<h2 id="정책-발전2">정책 발전2</h2>
<ul>
<li>agent는 Q함수값을 통해서 어느 행동이 좋은지를 비교할 수 있고, 좋은 행동이 정책으로 update될 수 있다. 이것을 탐욕정책으로 부른다. <br/></li>
</ul>
<p><a id="figure--"></a></p>
<p><figure><img src="./img/q_improv2.jpeg"
         alt="Figure 3: 정책발전2"/><figcaption>
            <p><span class="figure-number">Figure 3: </span>정책발전2</p>
        </figcaption>
</figure>
 <br/></p>
<h2 id="정책-평가와-정책-발전">정책 평가와 정책 발전</h2>
<ul>
<li>dp에선, 정책평가와 정책발전의 순서를 교차해서 진행해도 된다. <br/></li>
<li>정책평가는 주어진 정책을 계산해서 상태의 값을 update한다. 정책이 변경되면, 바뀐 정책에 따라 정책평가가 되기 때문에 순서에 대해 고민할 수 있는데, 상관없다. <br/></li>
<li>정책평가를 여러번하고, 정책발전을 하고 다시 정책평가를 해도 상관없다. <br/></li>
</ul>
<h2 id="가치-이터레이션">가치 이터레이션</h2>
<ul>
<li>정책 이터레이션은 정책이 분리가 되어 있다. 즉 주어진 정책에서 상태를 update하고, update된 상태를 기반으로 정책을 update하고, 이렇게 update된 정책으로 상태를 update한다. <br/></li>
<li>반면 가치 이터레이션은 처음부터 최적의 가치를 가지고 있다고 생각한다. 그래서 update를 할때, 최적의 값을 update한다. <br/></li>
</ul>
<p><a id="figure--"></a></p>
<p><figure><img src="./img/value_iteration0.jpeg"/>
</figure>
 <br/></p>
<h2 id="가치-이터레이션2">가치 이터레이션2</h2>
<ul>
<li>가치 이터레이션은 처음부터 상태들이 최적의 가치를 가지고 있다고 생각하기 때문에,탐욕적인 방식으로  동작한다. <br/></li>
</ul>
<h2 id="가치-이터레이션3">가치 이터레이션3</h2>
<ul>
<li>처음에는 최적의 가치는 아니지만, 이터레이션을 거쳐서 최적에 값에 수렴한다고 한다. update방식은 다음과 같다. <br/></li>
</ul>
<p><a id="figure--"></a></p>
<p><figure><img src="./img/value_iteration1.jpeg" width="500px" height="370px"/>
</figure>
 <br/></p>
<h2 id="다이나믹-프로그래밍의-한계">다이나믹 프로그래밍의 한계</h2>
<ul>
<li>dp로 MDP문제를 해결하기 위해선, 환경에 대한 완벽한 정보가 필요하다. <br/></li>
<li>차원이 증가할 수록 계산복잡도가 기하급수적으로 증가한다. (모든 상태를 동시에 전부 다 계산하기 때문) <br/></li>
</ul>
      
      </div>
        
  
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
  

  

  </div>
</div>  

<script src="/js/URI.js" type="text/javascript"></script>
<script src="/js/page.js" type="text/javascript"></script>
</body>
</html>
