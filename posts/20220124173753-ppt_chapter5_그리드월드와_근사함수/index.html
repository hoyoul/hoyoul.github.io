<!DOCTYPE html>
<html>
  <head><title>[ppt_chapter 5] 그리드월드와 근사함수</title>


<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="apple-mobile-web-app-capable" content="yes" />

<link rel="shortcut icon" href="./img/favicon.ico" type="image/x-icon">
<link rel="icon" href="./img/favicon.ico" type="image/x-icon">    

<link rel="stylesheet" href="/css/main.css">

</head>
  <body><header>
  <a href="/" id="logo">
    <img src="http://braindump.frege2godel.me/img/mylogo.png" alt="holy frege">
    <h3><span>H</span>oly <span>F</span>rege's <span id="note">notes</span></h3>
  </a>
    <small>G.frege를 너무 사랑하는 holy가...</small>  
</header>

<div class="container">
  <div class="page">
    <h1 class="collapsed-title">[ppt_chapter 5] 그리드월드와 근사함수</h1>    
      <div class="content">
	<a href="http://braindump.frege2godel.me/posts/20220124173753-ppt_chapter5_%E1%84%80%E1%85%B3%E1%84%85%E1%85%B5%E1%84%83%E1%85%B3%E1%84%8B%E1%85%AF%E1%86%AF%E1%84%83%E1%85%B3%E1%84%8B%E1%85%AA_%E1%84%80%E1%85%B3%E1%86%AB%E1%84%89%E1%85%A1%E1%84%92%E1%85%A1%E1%86%B7%E1%84%89%E1%85%AE/" alt="[ppt_chapter 5] 그리드월드와 근사함수" class="permalink"><h1>[ppt_chapter 5] 그리드월드와 근사함수</h1></a>      
	<h2 id="5장-요약">5장 요약</h2>
<ul>
<li>근사 함수를 사용하는 이유</li>
<li>근사 함수를 사용하는 방법</li>
<li>Deep SARSA 구현 (케라스 사용)</li>
</ul>
<h2 id="몬테카를로-살사-큐러닝의-한계">몬테카를로, 살사, 큐러닝의 한계</h2>
<h3 id="dp의-한계">DP의 한계</h3>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/dp1.jpeg"
         alt="Figure 1: DP의 한계"/><figcaption>
            <p><span class="figure-number">Figure 1: </span>DP의 한계</p>
        </figcaption>
</figure>

<h3 id="dp의-한계의-해결">DP의 한계의 해결</h3>
<ul>
<li>환경에 대한 정보 -&gt;  SALSA, Q-learning으로 해결</li>
<li>계산 복잡도, 차원의 저주 -&gt; 테이블 대신 근사함수로 해결</li>
</ul>
<h3 id="example">example</h3>
<ul>
<li>Grid world는 상태 개수가 얼마 안되서 table로 가능</li>
<li>table로 불가능한 예 (책에 나온 예: 상태의 정의가 다름에 유의)</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/gworld.jpeg"
         alt="Figure 2: grid world" width="450px"/><figcaption>
            <p><span class="figure-number">Figure 2: </span>grid world</p>
        </figcaption>
</figure>

<h2 id="근사함수를-통한-가치함수의-매개-변수화-1">근사함수를 통한 가치함수의 매개 변수화 1</h2>
<ul>
<li>SALSA나 Q-Learning에선 qtable의 값을 update시키고 action을 결정했다.</li>
<li>qtable을 매번 update하지 않고, qtable에 해당하는 함수의 parameter를 update한다면?</li>
</ul>
<h2 id="근사함수를-통한-가치함수의-매개-변수화-2">근사함수를 통한 가치함수의 매개 변수화 2</h2>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/function-1.jpeg"
         alt="Figure 3: function approximation1" width="330px"/><figcaption>
            <p><span class="figure-number">Figure 3: </span>function approximation1</p>
        </figcaption>
</figure>

<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/function-2.jpeg"
         alt="Figure 4: function approximation2" width="300px"/><figcaption>
            <p><span class="figure-number">Figure 4: </span>function approximation2</p>
        </figcaption>
</figure>

<h2 id="인공신경망">인공신경망</h2>
<h3 id="인공신경망의-개념">인공신경망의 개념</h3>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/neuron.jpeg"
         alt="Figure 5: neuron" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 5: </span>neuron</p>
        </figcaption>
</figure>

<ul>
<li>인간의 뇌에 있는 neuron을 모사.</li>
<li>모양이 아닌, 기능( 계산, 판단,추론)</li>
<li>학습이란 판단능력을 높이는 것임.</li>
</ul>
<h3 id="neuron의-구조">neuron의 구조</h3>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/neuron2.jpeg"
         alt="Figure 6: neuron 2" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 6: </span>neuron 2</p>
        </figcaption>
</figure>

<ul>
<li>neuron을 사용하면, and, or, not, nand 게이트를 만들수 있음.</li>
<li>and, or,not, nand로 컴퓨터도 만들수 있고, 계산기도 만들수 있음.</li>
<li>인간의 계산능력을 모사함.</li>
</ul>
<h3 id="xor문제">XOR문제</h3>
<ul>
<li>neuron은 하나의 linear한 직선을 나타냄.</li>
<li>xor을 하나의 neuron으로 해결할 수 없음.</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/xor1.png"
         alt="Figure 7: xor problem" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 7: </span>xor problem</p>
        </figcaption>
</figure>

<h3 id="xor-문제의-해결-hidden-layer">xor 문제의 해결 hidden layer</h3>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/xor2.png"
         alt="Figure 8: hidden layer (모두의 딥러닝2 참조)" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 8: </span>hidden layer (모두의 딥러닝2 참조)</p>
        </figcaption>
</figure>

<ul>
<li>평면을 휘어서 문제를 해결함.(hidden layer가 그 역할을 함)</li>
<li>hidden layer를 써도 선형(linear) 분류만 가능함.</li>
</ul>
<h3 id="activate-function이란">activate function이란</h3>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/nonlinear.png"
         alt="Figure 9: non linear (위 예는 엄밀히는 non-linear하지 않다.)" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 9: </span>non linear (위 예는 엄밀히는 non-linear하지 않다.)</p>
        </figcaption>
</figure>

<ul>
<li>activate function을 사용해서 nonlinear한 분류기를 만들 수 있다.</li>
</ul>
<h4 id="activate-function--linear">activate function(linear)</h4>
<ul>
<li>activate function이 linear하다면, linear분류를 할뿐이다.</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/linear1.png"
         alt="Figure 10: linear1" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 10: </span>linear1</p>
        </figcaption>
</figure>

<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/linear2.png"
         alt="Figure 11: linear2" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 11: </span>linear2</p>
        </figcaption>
</figure>

<h4 id="activate-function--non-linear">activate function( non-linear)</h4>
<ul>
<li>activate function이 non-linear하다면 아래와 같은 분류를 할 수 있다.</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/nonlinear1.png"
         alt="Figure 12: non-linear" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 12: </span>non-linear</p>
        </figcaption>
</figure>

<h3 id="sigmoid-활성-함수">sigmoid 활성 함수</h3>
<h4 id="sigmoid-수식">sigmoid 수식</h4>
<ul>
<li>0과 1의 연속적 값을 출력 (확률을 나타낼 수 있다.)</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/sigmoid.jpeg"
         alt="Figure 13: sigmoid" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 13: </span>sigmoid</p>
        </figcaption>
</figure>

<h4 id="sigmoid-수식과-그래프">sigmoid 수식과 그래프</h4>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/sigmoidgraph1.jpeg"
         alt="Figure 14: sigmoid graph1" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 14: </span>sigmoid graph1</p>
        </figcaption>
</figure>

<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/sigmoidgraph2.jpeg"
         alt="Figure 15: sigmoid graph2" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 15: </span>sigmoid graph2</p>
        </figcaption>
</figure>

<h3 id="relu-활성-함수">Relu 활성 함수</h3>
<h4 id="relu-함수의-수식">Relu 함수의 수식</h4>
<ul>
<li>ReLU(Rectified Linear Unit)는 요즘 가장 많이 쓰이는 활성함수.</li>
<li>입력이 0보다 크면 그대로 출력, 0보다 작으면 0으로 출력</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/relu1.jpeg"
         alt="Figure 16: Relu 수식" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 16: </span>Relu 수식</p>
        </figcaption>
</figure>

<h4 id="relu-함수의-그래프">Relu 함수의 그래프</h4>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/relu2.jpeg"
         alt="Figure 17: Relu graph" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 17: </span>Relu graph</p>
        </figcaption>
</figure>

<h3 id="layer와-활성화-함수와의-관계">Layer와 활성화 함수와의 관계</h3>
<h4 id="neuron의-그림">neuron의 그림</h4>
<ul>
<li>뉴론을 좀더 정확하게 표현 하면 아래와 같다.</li>
<li>선형결합값이 활성화 함수의 인자로 들어간다.</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/hlayer1.png" width="400px"/>
</figure>

<h4 id="여러개의-layer">여러개의 layer</h4>
<ul>
<li>복잡한 여러개의 layer에서도 마찬가지로 이전 layer의 값이 인자로 들어간다.</li>
<li>이전 layer를 함수로 표현하고 현재 layer를 함수로 표현했을때, 함수가 인자로 들어간다고 볼수 있다.</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/mlayer.png" width="400px"/>
</figure>

<h3 id="중간-정리">중간 정리</h3>
<ul>
<li>활성함수를 통해서 가중치와 입력의 합(linear)으로 부터 곡선(non-linear)을 만들 수 있었다.</li>
<li>곡선의 parameter(weight,bias)를 update 하는 것을 학습이라고 한다.</li>
<li>학습을 통해서 곡선 함수의 모양을 원하는 data에 맞추어 fitting하는 것이 목적</li>
<li>Relu와 sigmoid는 각각의 장단점이 있다. sigmoid가 gradient vanishing 문제로 Relu를 사용한다.
(구체적인 차이보다, Relu와 sigmoid는 non-linear한 신경망을 만들수 있다는 데 촛점을 두자)</li>
</ul>
<h3 id="딥러닝">딥러닝</h3>
<ul>
<li>딥러닝은 feature extraction이 자동으로 된다. 심층 신경망을 사용하면 가능하다.</li>
<li>심층신경망(Deep Neural network): hidden layer가 2개이상 가진 neural network.</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/deeplearning1.png"
         alt="Figure 19: deep learning 이전"/><figcaption>
            <p><span class="figure-number">Figure 19: </span>deep learning 이전</p>
        </figcaption>
</figure>

<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/deeplearning2.png"
         alt="Figure 20: deep learning"/><figcaption>
            <p><span class="figure-number">Figure 20: </span>deep learning</p>
        </figcaption>
</figure>

<h3 id="신경망의-학습">신경망의 학습</h3>
<ul>
<li>신경망의 학습: 가중치와 편향을 update.</li>
<li>supervised learning의 예</li>
<li>신경망 자체가 곡선의 방정식, trainning data를 입력하고, 정답과의 오차를 사용해서 곡선의 parameter를 수정한다.</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/learning1.png"
         alt="Figure 21: learning1" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 21: </span>learning1</p>
        </figcaption>
</figure>

<h4 id="오차의-계산--mse">오차의 계산 (MSE)</h4>
<ul>
<li>위에서 말했듯이, 입력을 넣었을때 정답이 나오지 않았을때, 오차가 발생한다.</li>
<li>오차를 계산하는데에는 MSE(Mean Squared Error)가 사용된다.</li>
<li>여기서 타깃은 output layer의 가중치가 들어간 함수로 표현할 수 있기 때문에 아래의 식은 loss function형태로 표현된다.</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/learning2.png" width="400px"/>
</figure>

<h4 id="경사-하강법">경사 하강법</h4>
<ul>
<li>우리가 원하는 학습은 loss function을 최소화하는 가중치를 update하는 것이다.</li>
<li>loss function은 가중치가 포함된 함수이기 때문에 편미분을 통해서 가중치를 update하면 된다.</li>
<li>어느 정도로 업데이트 해야 하는지는 알수가 없다. 단지, 다음과 같은 관계가 있다.</li>
<li>편미분 값이 큰 가중치 더 영향력이 있음을 알수 있다.</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/loss1.jpeg" width="400px"/>
</figure>

<h4 id="경사하강법">경사하강법</h4>
<ul>
<li>가중치를( w와 b)를 편미분 한 값은 변화율을 나타내고, 변화율의 크기와 learning rate를 곱한값으로 업데이트를 한다.</li>
<li>아래의 loss function을 보면, starting point의 편미분값이 0보다 작기때문에 조금 크게 해서 update를 하다 보면, 최종적으로 loss function이 최소화하는 값에 도달할 수 있다.</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/gdescent.jpeg"
         alt="Figure 22: gradient descent" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 22: </span>gradient descent</p>
        </figcaption>
</figure>

<h4 id="back-propagation">Back propagation</h4>
<ul>
<li>신경망은 여러개의 layer로 이루어져 있기 때문에 위에서 편미분한 값을 update할 때, 역방향으로 update를 하게 된다. 여러개의 layer를 거쳐야 하기 때문에 chain rule이 사용된다.</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/backpropa.jpeg" width="400px"/>
</figure>

<h2 id="딥살사-vs-살사">딥살사 vs 살사</h2>
<ul>
<li>딥살사: 신경망 사용하고 경사하강법으로 신경망을 update함.</li>
<li>살사:  q값을 table로 저장하고 table을 update함.</li>
<li>상태가 적을경우는 table에 저장하는 것이 문제가 되지 않는다.</li>
<li>딥살사와 살사의 차이점은 Q값을 table로 사용하느냐 or 근사함수(신경망)을 사용하느냐? 차이.</li>
<li>학습(update)하는 방식의 차이가 있다.</li>
</ul>
<h3 id="책에서-제시한-예제">책에서 제시한 예제</h3>
<ul>
<li>책에서 제시한 예제는 gridworld이긴 하나, 장애물이 움직이는 상황이다.</li>
<li>상태의 정의가 변경되었다.</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/dsalsa.jpeg"
         alt="Figure 23: deep salsa example" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 23: </span>deep salsa example</p>
        </figcaption>
</figure>

<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/dstatus.jpeg"
         alt="Figure 24: deep salsa state" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 24: </span>deep salsa state</p>
        </figcaption>
</figure>

<ul>
<li>한개의 상태는 15개의 값 (도착지점정보, 장애물 3개에 대한 정보)으로 구성된다.</li>
</ul>
<h2 id="딥-살사의-학습">딥 살사의 학습</h2>
<h3 id="딥살사의-학습">딥살사의 학습</h3>
<ul>
<li>살사가 TD로 Qtable을 update한다면, 딥 살사는 경사하강법으로 update한다.</li>
<li>실제 구현은 keras를 사용한다면, loss function만 정의하면 학습이 된다.</li>
<li>loss function은 정답과 예측의 차를 나타내야 하는데, 살사에서 사용된 Q update식을 참조한다.</li>
</ul>
<h3 id="딥살사의-학습의-정답과-예측">딥살사의 학습의 정답과 예측</h3>
<ul>
<li>살사에서는 1step 간후 거기서 얻은 실제 보상값과 다음에 대한 예측값이 사용되었다.</li>
<li>딥살사에서 정답과 예측으로 살사에서 사용된 값을 사용한다.</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/qvalue.png"
         alt="Figure 25: q learning value" width="500px"/><figcaption>
            <p><span class="figure-number">Figure 25: </span>q learning value</p>
        </figcaption>
</figure>

<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/qvalue1.png"
         alt="Figure 26: qvalue 정답" height="70px"/><figcaption>
            <p><span class="figure-number">Figure 26: </span>qvalue 정답</p>
        </figcaption>
</figure>

<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/qvalue2.png"
         alt="Figure 27: qvalue 예측" height="70px"/><figcaption>
            <p><span class="figure-number">Figure 27: </span>qvalue 예측</p>
        </figcaption>
</figure>

<h3 id="딥-살사의-구현-1">딥 살사의 구현 1</h3>
<ul>
<li>(1)과 (5)을 신경망을 이용할 뿐 기존의 살사와 큰 차이는 없다.</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/dsalsaimp.jpeg"
         alt="Figure 28: deep salsa flow"/><figcaption>
            <p><span class="figure-number">Figure 28: </span>deep salsa flow</p>
        </figcaption>
</figure>

<h3 id="딥-살사의-구현-2">딥 살사의 구현 2</h3>
<ul>
<li>(1)에서 다음 행동을 선택할때 신경망을 이용한다. 아래 그림에서 output값은 행동을 나타낸다.</li>
<li>(5)에서는 신경망을 학습한다.</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/dsalsaimp2.jpeg"
         alt="Figure 29: deep salsa flow 2" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 29: </span>deep salsa flow 2</p>
        </figcaption>
</figure>

<h3 id="요약-정리">요약 정리</h3>
<ul>
<li>딥 살사는 살사에서 Qtable을 update하는 방식이 신경망으로 바뀌었을뿐이다.</li>
<li>기존의 살사와 Q-learning처럼 정책은 필요가 없다.</li>
<li>e-greedy로 가장큰 Q값을 선택해서 행동하고 학습하거나, epsilon으로 행동하고 greedy로 학습하는 것은 같다.</li>
<li>책에서 설명하고 있는 구현부분은 생략했다. 기존의 살사에서  학습을 keras로 변경만 했다.</li>
</ul>
<h2 id="폴리시-그레이디언트">폴리시 그레이디언트</h2>
<h3 id="정책기반-강화학습">정책기반 강화학습</h3>
<ul>
<li>DP에서 정책기반 iteration을 사용했었다.</li>
<li>DP에서는 가치함수 table을 업데이트하고, 정책 table을 update하는 과정을 교대로 했다.</li>
<li>정책기반 강화학습에서는 가치함수 table 없이 정책을 직접 인공신경망으로 근사화한다.</li>
<li>가치함수 없이 구현하는 원리를 아는 것이 핵심이다.</li>
</ul>
<h3 id="정책기반-강화학습-인공-신경망">정책기반 강화학습 인공 신경망</h3>
<ul>
<li>신경망을 통한 정책함수로 보면된다. 상태를 입력으로 받아서 행동 확률을 출력한다.</li>
<li>확률을 출력하기 때문에 output layer의 활성함수는 sigmoid와 비슷한 softmax를 사용.</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/plearning1.jpeg"
         alt="Figure 30: policy neural network" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 30: </span>policy neural network</p>
        </figcaption>
</figure>

<h3 id="softmax-활성-함수-dot">softmax 활성 함수.</h3>
<ul>
<li>sigmoid와 softmax는 확률을 표현한다.</li>
<li>softmax는 출력 노드의 합이 1이 된다는 점에서 차이가 있다.</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/softmax.jpeg"
         alt="Figure 31: softmax activate function" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 31: </span>softmax activate function</p>
        </figcaption>
</figure>

<h3 id="폴리시-그레이디언트">폴리시 그레이디언트</h3>
<ul>
<li>정책기반 강화학습은 정책 iteration과 달리 가치 table을 인공신경망안에 녹였다.</li>
<li>가치 신경망이 학습해야 하는것은 누적보상이다.</li>
<li>딥살사의 인공신경망에서는 loss function을 통해서  신경망을 update했다면, 정책기반 강화학습에서는 목표가 다음과 같다. theta는 가중치를 나타낸다.</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/pgoal.jpeg"
         alt="Figure 32: policy gradient" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 32: </span>policy gradient</p>
        </figcaption>
</figure>

<h3 id="경사-상승법">경사 상승법</h3>
<ul>
<li>신경망을 하나의 곡선으로 보고, 여기서 편미분 한값을 update한다.</li>
<li>경사 하강법과 다르게 경사를 높이는 방향으로 이루어진다.</li>
<li>loss function처럼 목표함수를 theta로 편미분한다.</li>
</ul>
<h3 id="경사-상승법의-업데이트식">경사 상승법의 업데이트식</h3>
<ul>
<li>policy gradient의 미분은 shutton의 논문에서 소개한 정리를 따라서 구할 수 있다.</li>
<li>shutton의 정리에 따라 수식을 전개하면, 최종적으로 폴리시 그레이디언트의 업데이트식을 다음과 같이 구한다.</li>
<li>복잡하지만, keras에서는 직접 구하지 않는다.</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/pgradient.jpeg"
         alt="Figure 33: policy gradient" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 33: </span>policy gradient</p>
        </figcaption>
</figure>

<h3 id="reinforce-알고리즘">Reinforce 알고리즘</h3>
<ul>
<li>위의 policy gradient식에서는 미분 결과에는 q값이 필요하다.</li>
<li>하지만, 정책강화에서는 q값을 사용하지 않는다.</li>
<li>q값 대신에 반환값으로 대체한다.</li>
<li>즉 몬테카를로 방식처럼 에피소드가 끝나면 신경망의 미분값을 계산해서 update를 하는 것이다.</li>
</ul>
<p><a id="figure--"></a></p>
<figure><img src="./img/chapter5/reinforce1.jpeg"
         alt="Figure 34: reinforce algorithm" width="400px"/><figcaption>
            <p><span class="figure-number">Figure 34: </span>reinforce algorithm</p>
        </figcaption>
</figure>

      
      </div>
        
  
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
    
     
  

  

  </div>
</div>  

<script src="/js/URI.js" type="text/javascript"></script>
<script src="/js/page.js" type="text/javascript"></script>
</body>
</html>
